[
  {
    "objectID": "upcoming_courses.html",
    "href": "upcoming_courses.html",
    "title": "Upcoming Courses",
    "section": "",
    "text": "Core R\n\n\nLearn about R and RStudio in this introductory course.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNERC Metagenomics\n\n\nLearn more about metagenomics, a way to explore all the genetic material in an environmental sample.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Retreat\n\n\nJoin us for a code retreat to apply your new skills to your own data and network with other genomics researchers.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "upcoming/NERC Metagenomics/index.html",
    "href": "upcoming/NERC Metagenomics/index.html",
    "title": "NERC Metagenomics",
    "section": "",
    "text": "Register for Metagenomics(https://forms.gle/eJ3xWAb3Cy6wZVyk8)\n\n\n\n\n\n\nMetagenomics explores all the genetic material in an environmental sample. It can be used to characterise the taxonomic characteristics of microbial communities.\nThis online module will be delivered over a three-week period from Monday 6th to Friday 24th November 2023.\nMetagenomics analyses involve a lot of data and can take hours to days to complete! But don‚Äôt worry! The format of the workshop takes account of this. For longer analyses there will be scheduled online zoom sessions to cover concepts and get started followed by offline time for the analysis run and for you to complete some exercises. These will be supported by online drop-ins and a Slack channel for trouble-shooting.\n\nTarget audience\nUK based Environmental Science researchers at any career stage or anyone with an interest in Metagenomics. We assume no prior experience of the command line or high performance computing. Due to our funding, we prioritise places to researchers within the NERC remit.\nCheck out testimonials from previous attendees!\n\n‚ÄúThis course was fantastic in both helping me to understand the concepts behind metagenomic polishing/assembly processes and in actually learning how to do it ourselves. I have learnt a lot that I can confidently go and apply to my own research.‚Äù\n\n\n‚ÄúReally recommend this course! The content was great, covering command line fundamentals and the whole metagenomics workflow in a way that was really easy to understand. The team were super engaged and helpful throughout!‚Äù\n\n\n‚ÄúReally pleased with how the course was ran. The instructors were clear and patient, and the online course materials were thorough. I really enjoyed the taxonomic analysis as it brought everything we learned together. This course is super applicable for when I collect and analyse my data further into my PhD project. :)‚Äù\n\n\n\nRegistration\n\n\n\n\n\n\nRegister for Metagenomics\n\n\n\n\n\n\nThere are 30 places available for this online workshop, please register using the online form. Priority will be given to NERC funded students and researchers, as well as researchers from underrepresented groups, although we encourage everyone to apply. This course is free of charge.\nApplication deadline: 12pm Wednesday 18th October. Applicants will be notified by Monday 23rd October if they have been allocated a place. Scholarships and funding for headsets and monitors will be available.\n\n\nProgramme\nWe start by teaching the essential tools used in High Performance computing such as file systems and the command-line to connect to and use cloud computing for file navigation and script writing. We then introduce metagenomics and building a metagenomic assembly. In the second week, you will learn how to improve your assembly by ‚Äòpolishing‚Äô, separate your assembled metagenome into individual genomes (MAGS) and conduct taxonomic assignment and analysis. But if you can‚Äôt get something to work, we have a Slack channel and a weekly drop-in to help.\nWin ¬£25 in Amazon vouchers for showing commitment to your learning!\nAt Cloud-SPAN we know it‚Äôs difficult to find time to train so we‚Äôve come up with a little incentive for learners signed up for the online course. For the Metagenomics course there will be a prize draw and two people will win a ¬£25 Amazon voucher! All you have to do to enter the prize draw is go through the exercises - we will use your command history to verify your efforts. It doesn‚Äôt matter if you make mistakes or can‚Äôt get something to work, it is your commitment that matters!\nHappy learning!\nWeek 1\n\n\n\n\n\n\n\n\nMonday 6 November\n14:00 - 16:00\nCommand-line programming: file systems, files and directories\n\n\nTuesday 7 November\n14:00 - 16:00\nCommand-line programming: using the command line\n\n\nThursday 9 November\n10:00 - 13:30\nAn introduction to metagenomics, quality control and assembly.\n\n\n\n\nOffline time for assembly to complete.\n\n\n\nWeek 2\n\n\n\n\n\n\n\n\nMonday 13 November\n14:00 - 15:00\nOnline troubleshooting drop-in session (optional)\n\n\nWednesday 15 November\n10:00 - 11:30\nPolishing your metagenome assembly.\n\n\n\n\nOffline time for the polishing to complete\n\n\nFriday 17 November\n14:00 - 15:00\nOnline troubleshooting drop-in session (optional)\n\n\n\nWeek 3\n\n\n\n\n\n\n\n\nTuesday 21 November\n10:00 - 11:30\nBinning a metagenome assembly into individual genomes (MAGS)\n\n\n\n\nOffline time for the binning to complete\n\n\nTuesday 21 November\n10:00 - 11:00\nOnline troubleshooting drop-in session (optional)\n\n\nFriday 24 November\n13:00 - 16:00\nTaxonomic Assignment and Analysis\n\n\n\nIf you are unable to attend an online session, recordings will be distributed. You will have access to your instance until Friday 1 December (one week after the course is completed) to give you time to consolidate your learning. Usage of the instances will be monitored; instances which are inactive will be closed down as a daily charge is incurred.\nWe recommend workshop participants have a second monitor and a headset. Dual monitors allow you to engage with the trainers, view materials shared on screen and other participants on one monitor while doing the activities on another. To support you with your learning we have funding to provide you with a headset and a monitor if you require this. To request this additional funding please indicate this in the registration form. Funds for the monitors and headsets will be distributed at the end of course to those participants who regularly attended the online sessions.\n\n\nPre-requisites\nYou will need familiarity with biological concepts, including the concept of microbiome. We assume no prior experience of the command line or high performance computing. Windows users will need to install GitBash.\nYou don‚Äôt need to worry about installing metagenomics software or putting the data on your own computer! You will have access to an Amazon Web Services instance with all the data and software and will only need to log in to it.\n\n\nLearning outcomes\nFollowing completion of this course, learners will be able to:\n\nexplain the hierarchical structure of a file system and describe the files and file structure used in the course\nexplain what is meant by a working directory, a path and a relative path and write down paths that they will need for the course\nstart a Terminal (Mac) or Git Bash Terminal (Windows)\nnavigate a file system using the command line\nlog in to and exit their AWS instance (the cloud)\nuse common commands such as ls, pwd and cd, on the command line\nknow the difference between genomics and metagenomics\ndescribe the steps in a metagenomic workflow\nperform quality control on reads and assemble them into a metagenome\nperform polishing to improve an assembly\nuse binning to separate the metagenome into different species or MAGs (Metagenome-Assembled Genomes)\nuse Kraken 2 to assign taxonomy to reads and contigs and phyloseq in R to analyse taxonomic diversity\n\n\n\nScholarships and additional support\nWe recommend workshop participants have a second monitor and a headset. Dual monitors allow you to engage with the trainers, view materials shared on screen and other participants on one monitor while doing the activities on another. To support you with your learning we have funding to provide you with a headset and a monitor if you require this. To request this additional funding please indicate this in the registration form. Funds for the monitors and headsets will be distributed at the end of course to those participants who regularly attended the online sessions.\nWe offer scholarships to enable members of underrepresented groups and those with financial difficulties to participate in our training courses. Please complete the relevant section in the application form before 12pm on Wednesday 18th October."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Cloud-SPAN trains researchers, and the research software engineers that support them, to run specialised analyses on cloud-based high-performance computing (HPC) infrastructure.\n\nGenomics Course\nThis course is based on Carpentries materials introduces the foundations of Genomics andbBioinformatics and will take place three times, after which point it will be available as a self-study course. View further information on the Genomics course.\n\n\nAdvanced Modules\nAdvanced modules covering specialised knowledge and skills required to generate and analyse ‚Äôomics data using Cloud HPC resources will be delivered three times. These will include experimental design, statistical modules and deployment of cloud-based containerised instances for exemplar workflows. They will form a complete teaching and training resource that can be used for online tutor-led workshops or self-paced learning.\n\n\nCloud Administration Guides\nCloud Administration Guides will enable HPC workflows as ‚Äúproduction‚Äù instances which can be used by institutional RSE, RDM or HPC Teams to run or support specialised skills modules with their own resources. The Guides will be supported by in person training by Cloud-SPAN systems administrators.\n\n\nLearning Paths\nYou will have the flexibility to select different modules which differ in starting point and length to cater to researchers at a variety of careers stages with differing levels of previous experience.\n\n\nDiversity Scholarships\nUnderrepresented groups in research and HPC will be eligible to apply for financial support in order to participate in online or in-person training. View further information on scholarships.\n\n\nCode Retreats and Mentoring\nLearners will have have the opportunity to attend code retreats and benefit from mentoring to provide them both the skills and the self-confidence to apply methods to their own research questions and data.\n\n\nCommunity of Practice\nWe hope to establish a welcoming online community to support learners, including self-paced learners, in the application of training materials to their own research data."
  },
  {
    "objectID": "contact-us.html",
    "href": "contact-us.html",
    "title": "Contact us",
    "section": "",
    "text": "Email us at cloud-span-project@york.ac.uk if you have any questions or would like any additional information.\n\nFollow us\n\nConnect with us on LinkedIn\nFollow us on Twitter for updates on upcoming courses, blog posts and recent news on Genomics\nView our courses on GitHub"
  },
  {
    "objectID": "self_study/Genomics/index.html",
    "href": "self_study/Genomics/index.html",
    "title": "Genomics",
    "section": "",
    "text": "Info about Genomics"
  },
  {
    "objectID": "self_study/Create Your Own AWS Instance/index.html",
    "href": "self_study/Create Your Own AWS Instance/index.html",
    "title": "Create Your Own AWS Instance",
    "section": "",
    "text": "Info about Create Your Own AWS Instance"
  },
  {
    "objectID": "cloud-span-aims.html",
    "href": "cloud-span-aims.html",
    "title": "Our aims",
    "section": "",
    "text": "Challenges in Environmental ‚ÄôOmics\n\n\n  \n\nSoftware installation for data analysis is complex and involves multiple dependencies.\n\n\n\n  \n\nHPC architectures vary between institutions and accessibility is a lottery.\n\n\n\n  \n\nMetagenomic analyses involve large datasets and take a long time to run.\n\n\n\n  \n\nBig data ‚Äôomics analyses using HPC are not core skills for researchers and have a steep learning curve.\n\n\n\n\n\n\n\nSolutions\n\n\n  \n\nWe use cloud-based containerised instances with pre-installed software which are scalable and easy to access.\n\n\n\n  \n\nWe deliver high quality training with a low barrier to participation - absolutely zero previous experience needed!\n\n\n\n\n\n\nOur Approach\n\n\n  \n\nWe offer training in both self-study and workshop formats, with a mix of online and in-person teaching\n\n\n\n  \n\nWe are building a community of practice: a community of bioinformaticians who can support one another.\n\n\n\n  \n\nWe are following open science principles and making our resources FAIR (findable, accessible, interoperable, reusable)."
  },
  {
    "objectID": "blogs/05-31-22/index.html",
    "href": "blogs/05-31-22/index.html",
    "title": "What is FAIR data?",
    "section": "",
    "text": "At Cloud-SPAN we care deeply about making science as open as possible. A lot of this comes down to project management and data organisation - which we teach as part of our Genomics course. Today we want to introduce you to the FAIR data principles, which are a framework for thinking about how to ensure the scientific community gets the most out of the data we produce. In this case, this means making it easier for people to find and reuse our hard-earned data!\nThe FAIR framework aims to encourage data reuse by both humans and computers by improving the findability, accessibility, interoperability and reusability of data and other resources. So what are the steps involved in FAIR-ifying data?\n\n\nF is for Findable\nBefore data can be reused, we need to make sure it can be found. One way to do this is by tagging it with metadata (information about the data), such as what type of data it is, who collected it, the conditions used, and so on. This allows it to be indexed in a searchable registry so more people will see it. Metadata is important for both helping people find your data and for understanding the context they were generated in.\nAnother key way to make sure data is findable is by assigning it a persistent identifier. This is a long-lasting digital reference which ensures a resource can always be found, no matter where it's stored. DOIs (digital object identifiers) are one type of persistent identifier that you have probably heard of before - they can be applied to things like journal articles, data sets and other publications.\n\n\nA is for Accessible\nOnce we've made sure people can find our data, we need to make sure they can access it if they have permission. This means making it retrievable using some kind of standardised protocol, without any need for specialised or proprietary tools. We also need to tell people how they can get access, so we should include this as one of our metadata fields.\nA common misconception is that all FAIR data is 'open' or 'free'. Heavily protected or private data can still be FAIR as long as it is clear under which conditions the data is accessible.\n\n\nI is for Interoperable\nSo now we've made it possible for someone to find and access our data. How can we make sure they can actually use it? There are two aspects to interoperability. The first is using standardised and open formats so that data can be exchanged and used across multiple different applications and systems. This means avoiding proprietary formats and conforming with field-specific standards about what format data should come in.\nThe second relates to how computers understand our data in comparison with other data. This is possible using a 'controlled vocabulary' or 'ontology' which ensures that everyone is using the same words for the same thing. Again, we should try and conform with field-specific standards around ontologies.\n\n\nR is for Reusable\nThis final principle emphasises the idea that by following the previous three principles- findable, accessible, interoperable- we should be aiming to make our data as reusable as possible. This means using accurate and richly described metadata that gives a full overview of our experimental process and data analysis workflow.\nWe should also make it clear what rights the discoverer has when reusing our data. This is achieved by applying a licence, and clearly specifying this in the metadata. For example, a Creative Commons Attribution 4.0 International licence (or CC-BY for short) lets anyone reuse, remix and adapt material as long as credit is given to the original creator.¬†\n\n\nSummary\nThe FAIR framework guides us through ensuring that our data is easy to find, easy to understand and easy to reuse. This ensures that our data is used to the fullest extent possible.\nThe FAIR principles apply to digital objects beyond just data. At Cloud-SPAN we are working hard to make sure our learning resources are as FAIR as possible. Find out what we're doing to achieve this by visiting our handbook, or look out for our next blog post!\nFurther reading:\n\nThe 10 FAIR Principles\nPaper in Nature: The FAIR Guiding Principles for scientific data management and stewardship"
  },
  {
    "objectID": "blogs/12-14-21/index.html",
    "href": "blogs/12-14-21/index.html",
    "title": "Course Update",
    "section": "",
    "text": "Well, it‚Äôs been a couple of weeks since we ran our first course and we‚Äôve certainly learned a lot from it! Most of the problems we stumbled into were minor teething issues, but we‚Äôre also going to be making some fairly major changes based on what we learned. Here‚Äôs a bit of an update:\n\nFirst thing‚Äôs first... positive feedback!\nWe had some amazing feedback from our first run-through! We asked our participants to rate their level of comfort with a number of topics before and after completing the course.\nAs you can see in the graph below, on average our participants felt that their level of comfort had improved after taking the course for all topics. This is great news!\nIn particular, participants ended the course feeling really comfortable with using the command line to navigate file directories, create and modify files and search for keywords.\n\n\n\nThe BIG Problem: Time flies\nThe biggest problem we ran into was time. We just didn‚Äôt have enough of it...\n...and that means we need to seriously rethink how we structure the content of our course. You can see from the graph above that the topics people felt they had improved their confidence the least in were those relating to genomics - assessing read quality, trimming and filtering, and variant calling.\nThat‚Äôs because before we could teach those topics, we had to make sure people felt really comfortable using the command line and organising their files. Unfortunately, as we got more and more behind schedule, this meant the genomics topics got less and less time allocated to them.\nThis is a problem, because the title of the course was Foundational Genomics. If participants are finishing our course feeling like they are not comfortable with variant calling (which is what a score of 3 means) then we need to make some changes. Plus, the genomics bit is meant to be the fun bit!\nThe written feedback we had from participants after the course, while mostly positive, generally reflected this sentiment too.\n\n\nThe BIG Solution: Course structure\nIn light of this feedback, we‚Äôve decided to split our 4 x half-day Foundational Genomics course into two shorter courses: one 2 x half-day ‚ÄúPrenomics‚Äù course and one 4 x half-day ‚ÄúGenomics‚Äù course.\nThe Prenomics course will be aimed at complete beginners and will be a gentle introduction to file directories, working paths and basic command line commands. By giving ourselves two half-days to cover this content we should be able to ensure all participants are fully on board before we move onto anything more complex.\nThis course will also be optional for those who already have some basic experience using the command line. We plan to screen potential attendees using a self-test to help them determine whether they would benefit from attending the Prenomics course, or skipping straight to Genomics.\nThe Genomics course will follow directly on from Prenomics, using many of the same commands and building on them further. We should have much more time to cover essential topics such as read quality and variant calling which were rushed last time, allowing us to offer a much better educational experience.\n\n\nSome smaller problems which this change also solves...\n\nWe plan to run the Genomics course over two weeks, with 2 x half days per week. This, combined with a hopefully much less stressful volume of content to cover, will decrease pressure on our instructors and helpers, most of whom have multiple other work and teaching commitments.\nSome of our participants felt the course went far too slowly; others felt it went too fast. By screening for those who have the least experience working in the command line, we should be able to both provide more support to those who need it and stop more experienced participants from getting bored.\n\n\n\nOther updates in the pipeline\nThese two new courses, Prenomics and Genomics, will make up the ‚ÄòFoundational‚Äô element of our content. We still have plans to developed ‚ÄòAdvanced‚Äô modules on topics such as automation and setting up cloud instances. We asked our participants to let us know what they‚Äôd like to see, and we‚Äôll be taking these suggestions into account as we go.\nWe also have plans to run some (hopefully) in-person ‚Äòhack days‚Äô for alumni of our Foundational courses, where we can help participants apply the skills learned in the course to their own problems, and assist in troubleshooting any problems. We hope this will help develop our community of practice further by providing opportunities for networking and building relationships.\nAnd that‚Äôs it. Thanks for reading this far - we hope it explains some of our rationale for why the course is structured the way it is. We‚Äôre really proud of our achievements with our first ever course, and we‚Äôre looking forward to trying some new stuff out next time.\nTill next time! üëã"
  },
  {
    "objectID": "blogs/05-22-22/index.html",
    "href": "blogs/05-22-22/index.html",
    "title": "Genomics Self-Study now LIVE! üß¨",
    "section": "",
    "text": "We are pleased to announce that the registration for Genomics self-study is now live!¬†\nHere at Cloud-SPAN we recognise that all learners are individuals with specific needs and different levels of ability. This is why we have developed a Genomics ‚Äòself-study‚Äô option, where you can create your own schedule and learn at your own pace. These modules teach data management and analytical skills for genomic research.¬†\nHere‚Äôs how to get involved:\n\nStep 1 - Register!üìù\nThe educational materials are available free of charge, however we ask that you complete the registration form so we are able to send you updates and useful information.¬†\n\n\nStep 2 - Create your own instance‚õÖ\nStart with the ‚ÄòCreate your own instance‚Äô module, where you receive a step by step guide to creating your own Amazon Web Services instance. You will go on to use this instance to complete the subsequent Prenomics and Genomics modules.¬†¬†\n\n\nStep 3 - Prenomics üíª\nIf you are new to the realm of navigating file systems and using the command line we recommend that you complete the Prenomics module. We have designed this module to allow more time for those with less experience to cover some foundation concepts. If you aren‚Äôt sure how to gauge your skills take the self-assessment quiz to help you decide.¬†\n\n\nStep 4 - Genomicsüß¨\n¬†The Genomics module allows you to move on to the more fun stuff as you develop your skills in managing data. You will tackle tasks such as assessing read quality, trimming and filtering, and variant calling.¬†\n\n\nStep 5 - Community ü§∏‚Äç‚ôÇÔ∏è\nAfter completing the modules we hope that you will be able to attend one of our regular code retreats, where our course instructors will be on-hand to help solve any issues you encounter while applying your new skills to your own datasets. We also strongly encourage you to take advantage of our welcoming Cloud-SPAN community, so don‚Äôt be afraid to lean on your peers for help or discussions on our forum.¬†\n\n\nNeed support?\nJoin the Cloud-SPAN Slack workspace (you will receive a link upon registering), post on the forum or follow us on social media. All three are good options for you to continue on your mission to master the art of genomics!\nView the website for further information or drop us an email at cloud-span-project@york.ac.uk if you have any questions."
  },
  {
    "objectID": "self_study_courses.html",
    "href": "self_study_courses.html",
    "title": "Self-study Courses",
    "section": "",
    "text": "Register for our self-study courses.\n\n\n\n\n\n\n\n\n\n\nCreate Your Own AWS Instance\n\n\nLearn how to set up an Amazon Web Services instance.\n\n\n\n\n\npath\n\n\nhttps://cloud-span.github.io/create-aws-instance-0-overview/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrenomics\n\n\nLearn how to use the command line to navigate a file system and carry out simple tasks.\n\n\n\n\n\npath\n\n\nhttps://cloud-span.github.io/prenomics00-intro/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenomics\n\n\nLearn about data management and analytical skills for genomic research.\n\n\n\n\n\npath\n\n\nhttps://cloud-span.github.io/00genomics/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenomics for Environmental Scientists\n\n\nLearn more about metagenomics, a way to explore all the genetic material in an environmental sample.\n\n\n\n\n\npath\n\n\nhttps://cloud-span.github.io/nerc-metagenomics00-overview/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCore R\n\n\nLearn about R and RStudio in this introductory course.\n\n\n\n\n\npath\n\n\nhttps://github.com/Cloud-SPAN/core-r\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "self_study/Metagenomics for Microbiologists/index.html",
    "href": "self_study/Metagenomics for Microbiologists/index.html",
    "title": "Metagenomics for Microbiologists",
    "section": "",
    "text": "Info about Metagenomics for Microbiologists"
  },
  {
    "objectID": "self_study/Prenomics/index.html",
    "href": "self_study/Prenomics/index.html",
    "title": "Prenomics",
    "section": "",
    "text": "Info about Prenomics"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blogs",
    "section": "",
    "text": "What is FAIR data?\n\n\n\nOpen science\n\n\n\n\n\n\n\nEvelyn Greeves\n\n\nMay 31, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenomics Self-Study now LIVE! üß¨\n\n\n\nGenomics\n\n\nAnnouncements\n\n\n\n\n\n\n\nEvelyn Greeves\n\n\nMay 22, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nCourse Update\n\n\n\nGenomics\n\n\nBehind-the-scenes\n\n\n\n\n\n\n\nEvelyn Greeves\n\n\nDec 14, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "upcoming/Core R/index.html",
    "href": "upcoming/Core R/index.html",
    "title": "Core R",
    "section": "",
    "text": "Info about Core R\nThis online two-hour workshop is an introduction to R for complete beginners. It teaches you how to find your way round RStudio, use the basic data types and structures in R and how to organise your work with scripts and projects. It also teaches you how to import data, summarise it and create and format a graph. The workshop assumes no prior experience of coding.\n\nLearning outcomes\nBy the end of the course you will be able to;\n\nfind your way around RStudio\nuse the basic data types and structures in R\norganise your work with scripts and projects\nimport data, summarise it and create and format a graph\nThe workshop assumes no prior experience of coding.\n\n\n\nRegistration\nRegistration for this course is now closed.\nThere are 30 places available for this online course. Priority will be given to NERC funded students and researchers, as well as researchers from underrepresented groups, although we encourage everyone to apply. This course is free of charge.\nApplication deadline: 12pm Monday 5th June. Applicants will be notified by Tuesday 6th June if they have been allocated a place. Scholarships and funding for headsets and monitors will be available. Scholarships and additional support\nWe recommend workshop participants have a second monitor and a headset. Dual monitors allow you to engage with the trainers, view materials shared on screen and other participants on one monitor while doing the activities on another. To support you with your learning we have funding to provide you with a headset and a monitor if you require this. To request this additional funding please indicate this in the registration form. Funds for the monitors and headsets will be distributed at the end of workshop to those participants who attend the session.\nWe offer Scholarships to enable members of underrepresented groups and those with financial difficulties to participate in our training courses. To apply for a scholarship please complete the relevant questions in the registration form before the deadline. Submissions after this date will not be considered. All applicants will be notified of the results 2-3 days after the submission deadline."
  },
  {
    "objectID": "upcoming/Code Retreat/index.html",
    "href": "upcoming/Code Retreat/index.html",
    "title": "Code Retreat",
    "section": "",
    "text": "Info about the Code Retreats\nOur next Code Retreats will take place 12 till 3 pm on Friday 8th December 2023 and 11:00 am till 2pm Tuesday 16th January 2024 at the University of York. Our instructors will be on hand to help you problem-solve the issues that arise as you work. Lunch will be provided and funding is available to support travel to the Code Retreat.\nCloud-SPAN Alumni contact cloud-span-project@york.ac.uk to register and invitations will be distributed shortly."
  },
  {
    "objectID": "upcoming/Code Retreat/index.html#what-could-you-achieve",
    "href": "upcoming/Code Retreat/index.html#what-could-you-achieve",
    "title": "Code Retreat",
    "section": "What could you achieve?",
    "text": "What could you achieve?\n\nWorking with your peers and with help from our instructors, you could:\nRevise our Metagenomics course\nGet help organising and documenting your own analysis\nApply tools taught in Metagenomics to your own data\nGet help with Creating your own Amazon Web Services instance for Genomics\nNetwork with other genomics researchers"
  },
  {
    "objectID": "upcoming/Code Retreat/index.html#pre-requisites",
    "href": "upcoming/Code Retreat/index.html#pre-requisites",
    "title": "Code Retreat",
    "section": "Pre-requisites",
    "text": "Pre-requisites\n\nAttendees should have completed the a Cloud-SPAN course\nAttendees will need to bring their own laptop to this event"
  }
]